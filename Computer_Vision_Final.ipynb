{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Computer-Vision-Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "FuzsoKdzUghM",
        "Po568zVhUu8k",
        "QIiPiDoxVQsx",
        "9Mj4NrV1XFpB",
        "VPCEPMRnYa5m",
        "SOJayo9jZEEl",
        "Yli1JV8paDsE",
        "kxy8CO28aNLC",
        "LLhbcmABb6JF",
        "gbTe4d-tcCHU",
        "0Tt_HAEUbxkb",
        "4gA8hORtag5j",
        "Wt4M7D31bCKj",
        "LJ8ENvQVbHtw"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Krntud63UOUm"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29RWqqVZUSPY"
      },
      "source": [
        "texte explicatif du contenu du code et le but de ce projet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J0DLDLhUXY3"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuzsoKdzUghM"
      },
      "source": [
        "## Mounting the drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUCZVAmcUIrP"
      },
      "source": [
        "#mounting the drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HspxpZf0UlnH"
      },
      "source": [
        "#drive path\r\n",
        "drive_path = \"drive/My Drive/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Po568zVhUu8k"
      },
      "source": [
        "## Importing the images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzS2ghOfUx85"
      },
      "source": [
        "#unzipping the images from the drive into the local environment\r\n",
        "import zipfile\r\n",
        "with zipfile.ZipFile(drive_path+\"ProjetDL/images.zip\",\"r\") as zip_ref:\r\n",
        "  zip_ref.extractall(\"lesimages/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZo8jtMUU4n2"
      },
      "source": [
        "#checking the loading\r\n",
        "import os\r\n",
        "root = 'lesimages/img_align_celeba'\r\n",
        "img_list = os.listdir(root)\r\n",
        "print(len(img_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR3eRU4_VAdR"
      },
      "source": [
        "## Other imports needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "at1BO8xcVEE7"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torch.utils import data\r\n",
        "from torchvision import transforms as T\r\n",
        "from torchvision.datasets import ImageFolder\r\n",
        "from PIL import Image\r\n",
        "import torch\r\n",
        "import os\r\n",
        "import random\r\n",
        "from torch.autograd import Variable\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.init as init\r\n",
        "from torch.nn import Linear, Conv2d, BatchNorm2d, MaxPool2d, Dropout2d\r\n",
        "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\r\n",
        "import torch.optim as optim\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIiPiDoxVQsx"
      },
      "source": [
        "# Creating the sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmtJpAwvVYQt"
      },
      "source": [
        "## The DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJsc5Y0iVbzu"
      },
      "source": [
        "dire qu'on s'est bas√© sur le repo github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J195GWeVfFu"
      },
      "source": [
        "class CelebA(data.Dataset):\r\n",
        "    \"\"\"Dataset class for the CelebA dataset.\"\"\"\r\n",
        "\r\n",
        "    def __init__(self, image_dir, attr_path,  split_path, selected_attrs, transform, mode):\r\n",
        "        \"\"\"Initialize and preprocess the CelebA dataset.\"\"\"\r\n",
        "        self.image_dir = image_dir\r\n",
        "        self.attr_path = attr_path\r\n",
        "        self.split_path = split_path\r\n",
        "        self.selected_attrs = selected_attrs\r\n",
        "        self.transform = transform\r\n",
        "        self.mode = mode\r\n",
        "        self.train_dataset = []\r\n",
        "        self.train_dataset_with_added_bald = []\r\n",
        "        self.test_dataset = []\r\n",
        "        self.valid_dataset = []\r\n",
        "        self.all_dataset = []\r\n",
        "        self.all_dataset_with_added_bald = []\r\n",
        "        self.attr2idx = {}\r\n",
        "        self.idx2attr = {}\r\n",
        "        self.preprocess()\r\n",
        "\r\n",
        "        if mode == 'train':\r\n",
        "            self.num_images = len(self.train_dataset)\r\n",
        "        elif mode == 'valid':\r\n",
        "            self.num_images = len(self.valid_dataset)\r\n",
        "        else:\r\n",
        "            self.num_images = len(self.test_dataset)\r\n",
        "\r\n",
        "    def preprocess(self):\r\n",
        "        \"\"\"Preprocess the CelebA attribute file.\"\"\"\r\n",
        "        dict_split = dict()\r\n",
        "        lines = [line.rstrip() for line in open(self.split_path, 'r')]\r\n",
        "        for line in lines:\r\n",
        "          split = line.split()\r\n",
        "          dict_split[split[0]]=int(split[1])\r\n",
        "\r\n",
        "        lines = [line.rstrip() for line in open(self.attr_path, 'r')]\r\n",
        "        all_attr_names = lines[1].split()\r\n",
        "        for i, attr_name in enumerate(all_attr_names):\r\n",
        "            self.attr2idx[attr_name] = i\r\n",
        "            self.idx2attr[i] = attr_name\r\n",
        "\r\n",
        "        lines = lines[2:]\r\n",
        "        random.seed(1234)\r\n",
        "        random.shuffle(lines)\r\n",
        "        for i, line in enumerate(lines):\r\n",
        "            split = line.split()\r\n",
        "            filename = split[0]\r\n",
        "            values = split[1:]\r\n",
        "\r\n",
        "            label = []\r\n",
        "            all_label = []\r\n",
        "\r\n",
        "            for attr_name in self.attr2idx.keys():\r\n",
        "                idx = self.attr2idx[attr_name]\r\n",
        "                all_label.append(values[idx] == '1')\r\n",
        "            for attr_name in self.selected_attrs:\r\n",
        "                idx = self.attr2idx[attr_name]\r\n",
        "                label.append(values[idx] == '1')\r\n",
        "\r\n",
        "            if (self.mode == 'train'):\r\n",
        "              if (dict_split[filename] == 0):\r\n",
        "\r\n",
        "##### --- Uncomment the following lines in order to introduce data into de sets (repetition of images with a chosen attribute) --- #####\r\n",
        "                # if all_label[4] == True:\r\n",
        "                #   for i in range(1,10):\r\n",
        "                #     im = Image.open(\"lesimages/img_align_celeba/\"+filename) \r\n",
        "                #     im.save(\"lesimages/img_align_celeba/new_image_\"+filename.split(\".\")[0]+str(i)+\".png\")\r\n",
        "                #     self.train_dataset.append([\"new_image_\"+filename.split(\".\")[0]+str(i)+\".png\",label])\r\n",
        "                #     self.all_dataset.append([\"new_image_\"+filename.split(\".\")[0]+str(i)+\".png\", all_label])\r\n",
        "\r\n",
        "                self.train_dataset.append([filename, label])\r\n",
        "                self.all_dataset.append([filename, all_label])\r\n",
        "            elif (self.mode == 'valid'):\r\n",
        "              if (dict_split[filename] == 1):\r\n",
        "                self.valid_dataset.append((filename, label))\r\n",
        "                self.all_dataset.append([filename, all_label])\r\n",
        "            else:\r\n",
        "              if (dict_split[filename] == 2):\r\n",
        "                self.test_dataset.append((filename, label))\r\n",
        "                self.all_dataset.append([filename, all_label])\r\n",
        "\r\n",
        "        print('Finished preprocessing the CelebA dataset...')\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        \"\"\"Return one image and its corresponding attribute label.\"\"\"\r\n",
        "        dataset = self.train_dataset if self.mode == 'train' else self.valid_dataset if self.mode == 'valid' else self.test_dataset\r\n",
        "        filename, label = dataset[index]\r\n",
        "        image = Image.open(os.path.join(self.image_dir, filename))\r\n",
        "        return self.transform(image), torch.FloatTensor(label)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        \"\"\"Return the number of images.\"\"\"\r\n",
        "        return self.num_images\r\n",
        "\r\n",
        "\r\n",
        "def get_loader(image_dir, attr_path, selected_attrs,  split_path, crop_size=178, image_size=128, \r\n",
        "               batch_size=16, dataset='CelebA', mode='train', num_workers=1):\r\n",
        "    \"\"\"Build and return a data loader.\"\"\"\r\n",
        "    transform = []\r\n",
        "    if mode == 'train':\r\n",
        "        transform.append(T.RandomHorizontalFlip())\r\n",
        "    transform.append(T.CenterCrop(crop_size))\r\n",
        "    transform.append(T.Resize(image_size))\r\n",
        "    transform.append(T.ToTensor())\r\n",
        "    transform.append(T.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)))\r\n",
        "    transform = T.Compose(transform)\r\n",
        "\r\n",
        "    if dataset == 'CelebA':\r\n",
        "        dataset = CelebA(image_dir, attr_path, split_path, selected_attrs, transform, mode)\r\n",
        "    elif dataset == 'RaFD':\r\n",
        "        dataset = ImageFolder(image_dir, transform)\r\n",
        "\r\n",
        "    data_loader = data.DataLoader(dataset=dataset,\r\n",
        "                                  batch_size=batch_size,\r\n",
        "                                  shuffle=(mode=='train'),\r\n",
        "                                  num_workers=num_workers)\r\n",
        "    return data_loader, dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3RSHPoWV9wb"
      },
      "source": [
        "## Creating the sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuEv_xv2WaoG"
      },
      "source": [
        "### Common variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v1sqe2pWdQk"
      },
      "source": [
        "#image directiory :\r\n",
        "celeba_image_dir = \"lesimages/img_align_celeba/\"\r\n",
        "#split\r\n",
        "split_path = drive_path+\"ProjetDL/list_eval_partition.txt\"\r\n",
        "#attributes\r\n",
        "attr_path = drive_path+\"ProjetDL/list_attr_celeba.txt\"\r\n",
        "#selected attribute :\r\n",
        "#selected_attrs = ['Attractive']\r\n",
        "selected_attrs = [\"Attractive\"]\r\n",
        "#crop size\r\n",
        "celeba_crop_size = 178\r\n",
        "#image size\r\n",
        "image_size = 128\r\n",
        "#batch_size\r\n",
        "batch_size = 24\r\n",
        "#num workers\r\n",
        "num_workers = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_gGUOGhWf2l"
      },
      "source": [
        "### Train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfUM1yS2Wi5l"
      },
      "source": [
        "mode = 'train'\r\n",
        "trainloader, trainset = get_loader(celeba_image_dir, attr_path, selected_attrs, split_path,\r\n",
        "                                   celeba_crop_size, image_size, batch_size,\r\n",
        "                                   'CelebA', mode, num_workers)\r\n",
        "\r\n",
        "trainset_allattr = trainset.all_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz_Z1v2ZWm2n"
      },
      "source": [
        "### Validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_PhIWCpWqIe"
      },
      "source": [
        "mode = 'valid'\r\n",
        "\r\n",
        "validloader, validset = get_loader(celeba_image_dir, attr_path, selected_attrs, split_path,\r\n",
        "                                   celeba_crop_size, image_size, batch_size,\r\n",
        "                                   'CelebA', mode, num_workers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwLYLCNJWxQo"
      },
      "source": [
        "### Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yrOgOfuW2Wu"
      },
      "source": [
        "mode = 'test'\r\n",
        "\r\n",
        "testloader, testset = get_loader(celeba_image_dir, attr_path, selected_attrs, split_path,\r\n",
        "                                   celeba_crop_size, image_size, batch_size,\r\n",
        "                                   'CelebA', mode, num_workers)\r\n",
        "\r\n",
        "testset_allattr = testset.all_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXCMrgv0Xl6b"
      },
      "source": [
        "## Printing some images\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0NyP5yFXou4"
      },
      "source": [
        "train_data_iter = iter(trainloader)\r\n",
        "test_data_iter = iter(testloader)\r\n",
        "\r\n",
        "classes = ['Unattractive', 'Attractive']\r\n",
        "def imshow(img):\r\n",
        "    \"\"\" show an image \"\"\"\r\n",
        "    img = img / 2 + 0.5 # unnormalize\r\n",
        "    npimg = img.numpy()\r\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "\r\n",
        "\r\n",
        "# get some random training images\r\n",
        "images, labels = train_data_iter.next()\r\n",
        "\r\n",
        "# show images\r\n",
        "imshow(torchvision.utils.make_grid(images))\r\n",
        "\r\n",
        "# print labels\r\n",
        "print('  '.join('%5s' % classes[int(labels[j].item())] for j in range(batch_size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mj4NrV1XFpB"
      },
      "source": [
        "# Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVoYYN8nXe7u"
      },
      "source": [
        "## Model variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytLbvk4pX2U2"
      },
      "source": [
        "x, y = next(iter(trainloader))\r\n",
        "print(\"Batch dimension [B x C x H x W]:\", x.shape)\r\n",
        "channels_from_iter = x.shape[1]\r\n",
        "height_from_iter = x.shape[2]\r\n",
        "width_from_iter = x.shape[3]\r\n",
        "\r\n",
        "#hyperparameters for the model\r\n",
        "num_classes = len(selected_attrs) #number of classes depending on what we keep\r\n",
        "#print(trainset.data.shape)\r\n",
        "channels = channels_from_iter\r\n",
        "#print(channels)\r\n",
        "height = height_from_iter\r\n",
        "#print(height)\r\n",
        "width = width_from_iter\r\n",
        "#print(width)\r\n",
        "\r\n",
        "#first convolution\r\n",
        "num_filters_conv1 = 96\r\n",
        "kernel_size_conv1 = 3 # [height, width]\r\n",
        "stride_conv1 = 1 # [stride_height, stride_width]\r\n",
        "padding_conv1 = 1\r\n",
        "\r\n",
        "#second convolution\r\n",
        "num_filters_conv2 = 128\r\n",
        "kernel_size_conv2 = 4 # [height, width]\r\n",
        "stride_conv2 = 2 # [stride_height, stride_width]\r\n",
        "padding_conv2 = 2\r\n",
        "\r\n",
        "#hidden layer\r\n",
        "num_l1 = 96"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mhq2NjRJYKt8"
      },
      "source": [
        "## Defining the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Yi9eoZYMiG"
      },
      "source": [
        "def compute_conv_dim(dim_size):\r\n",
        "    return int((dim_size - kernel_size_conv2 + 2 * padding_conv2) / stride_conv2 + 1)\r\n",
        "\r\n",
        "class Net(nn.Module):\r\n",
        "    def __init__(self, num_classes):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.num_classes = num_classes\r\n",
        "        \r\n",
        "        #first convolution\r\n",
        "        self.conv_1 = Conv2d(in_channels=channels,\r\n",
        "                             out_channels=num_filters_conv1,\r\n",
        "                             kernel_size=kernel_size_conv1,\r\n",
        "                             stride=stride_conv1,\r\n",
        "                             padding=padding_conv1)\r\n",
        "        \r\n",
        "        self.batch_norm1 = BatchNorm2d(num_filters_conv1)\r\n",
        "        \r\n",
        "\r\n",
        "        self.conv_2 = Conv2d(in_channels=num_filters_conv1,\r\n",
        "                             out_channels=num_filters_conv2,\r\n",
        "                             kernel_size=kernel_size_conv2,\r\n",
        "                             stride=stride_conv2,\r\n",
        "                             padding=padding_conv2)\r\n",
        "        \r\n",
        "        self.batch_norm2 = BatchNorm2d(num_filters_conv2)\r\n",
        "        \r\n",
        "        self.conv_out_height = compute_conv_dim(height)\r\n",
        "        self.conv_out_width = compute_conv_dim(width)\r\n",
        "\r\n",
        "\r\n",
        "        self.l1_in_features = num_filters_conv2 * self.conv_out_height * self.conv_out_width\r\n",
        " \r\n",
        "\r\n",
        "        #first layer\r\n",
        "        self.l_1 = Linear(in_features=self.l1_in_features, #dense hidden layer\r\n",
        "                          out_features=num_l1,\r\n",
        "                          bias=True)\r\n",
        "        self.dropout = Dropout2d(p=0.3)\r\n",
        "        #output layer\r\n",
        "        self.l_out = Linear(in_features=num_l1, \r\n",
        "                            out_features=num_classes,\r\n",
        "                            bias=False)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "      x = relu(self.conv_1(x))\r\n",
        "      x = self.batch_norm1(x)\r\n",
        "      x = relu(self.conv_2(x))\r\n",
        "      x = self.batch_norm2(x)\r\n",
        "      x = x.view(-1, self.l1_in_features)\r\n",
        "      x = relu(self.l_1(x))\r\n",
        "      x = self.dropout(x)\r\n",
        "      return torch.sigmoid(self.l_out(x))\r\n",
        "    \r\n",
        "\r\n",
        "net = Net(num_classes)\r\n",
        "net.cuda()\r\n",
        "print(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPCEPMRnYa5m"
      },
      "source": [
        "# Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HesUcSqYdS4"
      },
      "source": [
        "## Defining a loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1snY1imYfwW"
      },
      "source": [
        "criterion = nn.BCELoss()  # Your code here!\r\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsVqxwY8Yt90"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc4BY5SaYwFP"
      },
      "source": [
        "num_epoch = 4  # Your code here!\r\n",
        "\r\n",
        "train_iter = []\r\n",
        "train_loss = []\r\n",
        "train_accs = []\r\n",
        "valid_iter = []\r\n",
        "valid_loss = []\r\n",
        "valid_accs = []\r\n",
        "\r\n",
        "log_every = 1000\r\n",
        "eval_every = 1000\r\n",
        "\r\n",
        "from IPython.display import clear_output\r\n",
        "\r\n",
        "for epoch in range(num_epoch):  # loop over the dataset multiple times\r\n",
        "\r\n",
        "    running_loss = 0.0\r\n",
        "    net.train()\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "\r\n",
        "    correct_valid = 0\r\n",
        "    total_valid = 0\r\n",
        "    for i, data in enumerate(trainloader, 0):\r\n",
        "\r\n",
        "##### --- Uncomment this part in order to do the validation as well --- #####\r\n",
        "        # if (i % eval_every == 0):\r\n",
        "        #   net.eval()\r\n",
        "        #   val_losses,val_accs,val_length = 0,0,0\r\n",
        "        #   with torch.no_grad():\r\n",
        "        #     for j,data in enumerate(validloader,0):\r\n",
        "        #       inputs_valid,labels_valid = data\r\n",
        "        #       inputs_valid, labels_valid = inputs_valid.cuda(), labels_valid.cuda()\r\n",
        "\r\n",
        "        #       output_valid = net(inputs_valid)\r\n",
        "        #       predicted_valid = torch.round(output_valid.data)\r\n",
        "        #       correct_valid += (predicted_valid == labels_valid).sum()\r\n",
        "        #       total_valid += labels_valid.size(0)\r\n",
        "\r\n",
        "        #       val_losses += criterion(output_valid,labels_valid).item()\r\n",
        "        #       val_accs += 100 * correct_valid.true_divide(total_valid)\r\n",
        "        #       val_length += 1 \r\n",
        "\r\n",
        "        #     valid_iter.append(i+len(trainloader)*epoch)\r\n",
        "        #     valid_loss.append(val_losses/val_length)\r\n",
        "        #     valid_accs.append(val_accs/val_length)\r\n",
        "\r\n",
        "        net.train()\r\n",
        "        inputs, labels = data\r\n",
        "\r\n",
        "        # wrap them in Variable\r\n",
        "        inputs, labels = inputs.cuda(), labels.cuda()\r\n",
        "        # zero the parameter gradients\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        #forward\r\n",
        "        output = net(inputs)\r\n",
        "        loss = criterion(output, labels)\r\n",
        "        #backward\r\n",
        "        loss.backward()\r\n",
        "\r\n",
        "        #optimize\r\n",
        "        optimizer.step()\r\n",
        "\r\n",
        "\r\n",
        "        # print statistics\r\n",
        "        running_loss += loss.item()\r\n",
        "\r\n",
        "        predicted = torch.round(output.data)\r\n",
        "        correct += (predicted == labels).sum()\r\n",
        "        total += labels.size(0)\r\n",
        "\r\n",
        "        if i %100 == 99:\r\n",
        "          train_iter.append(i+len(trainloader)*epoch)\r\n",
        "          train_loss.append(float(running_loss / 100))\r\n",
        "          running_loss = 0.0\r\n",
        "          accuracy = 100 * correct.true_divide(total)\r\n",
        "          train_accs.append(float(accuracy))\r\n",
        "          total = 0\r\n",
        "          correct = 0\r\n",
        "\r\n",
        "        if i % log_every == 0:\r\n",
        "            fig = plt.figure(figsize=(12,4))\r\n",
        "            plt.subplot(1, 2, 1)\r\n",
        "            plt.plot(train_iter, train_loss, label='train_loss')\r\n",
        "\r\n",
        "##### --- Uncomment the following line in order to plot the validation evolution --- #####\r\n",
        "            # plt.plot(valid_iter, valid_loss, label='valid_loss')\r\n",
        "            plt.xlabel(\"Number of batches\")\r\n",
        "            plt.ylabel(\"Mean Loss of the 100 previous batches\")\r\n",
        "            plt.title(\"Loss of the model over the batches\")\r\n",
        "            plt.legend()\r\n",
        "\r\n",
        "            plt.subplot(1, 2, 2)\r\n",
        "            plt.plot(train_iter, train_accs, label='train_accs')\r\n",
        "          \r\n",
        "##### --- Uncomment the following line in order to plot the validation evolution --- #####\r\n",
        "            # plt.plot(valid_iter, valid_accs, label='valid_accs')\r\n",
        "            plt.legend()\r\n",
        "            plt.title(\"Accuracy of the model over the batches\")\r\n",
        "            plt.ylabel(\"Accuracy\")\r\n",
        "            plt.xlabel(\"Number of batches\")\r\n",
        "            plt.show()\r\n",
        "            clear_output(wait=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOJayo9jZEEl"
      },
      "source": [
        "# Loading the trained model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrVG_hjRZGvu"
      },
      "source": [
        "expliquer que comme √ßa prend pas mal de temps, on peut direct les t√©l√©charger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPgDmxkgZPUh"
      },
      "source": [
        "## The model trained without added data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-1zJ26pZR2i"
      },
      "source": [
        "PATH = drive_path+\"ProjetDL/testdata_without.pth\"\r\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYeBtULjZnOM"
      },
      "source": [
        "## The model trained with added data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QASZya0lZpWK"
      },
      "source": [
        "PATH = drive_path+\"ProjetDL/testdata_with.pth\"\r\n",
        "net.load_state_dict(torch.load(PATH))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoAkHSx5aBHI"
      },
      "source": [
        "# Viewing the results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yli1JV8paDsE"
      },
      "source": [
        "## Testing the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_QolCvXa1HC"
      },
      "source": [
        "un petit texte pour expliquer quel mod√®le charger + quoi commenter/decommenter dans le dataloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kxy8CO28aNLC"
      },
      "source": [
        "### Creating the dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcQE7jlCaF6J"
      },
      "source": [
        "##### TEST DATAFRAME #####\r\n",
        "test_df_without_data = pd.DataFrame(testset_allattr)\r\n",
        "test_df_without_data.columns = [\"image_link\",\"attrs\"]\r\n",
        "test_df_without_data[[key for key in testset.attr2idx.keys()]] = test_df_without_data['attrs'].apply(pd.Series)\r\n",
        "test_df_without_data.pop(\"attrs\")\r\n",
        "test_df_without_data[\"status\"]=[\"Not_known_yet\" for i in range(len(test_df_without_data.index))]\r\n",
        "test_df_without_data[\"predicted_value\"]=[str(0) for i in range(len(test_df_without_data.index))]\r\n",
        "\r\n",
        "##### TRAIN DATAFRAME #####\r\n",
        "train_df_without_data = pd.DataFrame(trainset_allattr)\r\n",
        "train_df_without_data.columns = [\"image_link\",\"attrs\"]\r\n",
        "train_df_without_data[[key for key in trainset.attr2idx.keys()]] = train_df_without_data['attrs'].apply(pd.Series)\r\n",
        "del train_df_without_data[\"attrs\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDdMCjz5aZar"
      },
      "source": [
        "### Accuracy of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPaCs3BmacJU"
      },
      "source": [
        "correct = 0\r\n",
        "total = 0\r\n",
        "idx = 0 \r\n",
        "not_predicted_as_attractive_idx_without_data = []\r\n",
        "\r\n",
        "net.eval()\r\n",
        "for data in testloader:\r\n",
        "    images, labels = data\r\n",
        "    labels = labels.cuda()\r\n",
        "    outputs = net(images.cuda())\r\n",
        "    predicted_raw = outputs.data\r\n",
        "    predicted = torch.round(outputs.data)\r\n",
        "    predicted = predicted.cuda()\r\n",
        "    total += labels.size(0)\r\n",
        "    correct += (predicted == labels).sum()\r\n",
        "    for predict,predict_raw, real in zip(predicted,predicted_raw,labels):\r\n",
        "      test_df_without_data.at[idx,\"predicted_value\"] = str(predict_raw.item())\r\n",
        "      if predict==real:\r\n",
        "        if real==1:\r\n",
        "          test_df_without_data.at[idx,\"status\"] = \"True Positive\"\r\n",
        "        else:\r\n",
        "          test_df_without_data.at[idx,\"status\"] = \"True Negative\"\r\n",
        "      else:\r\n",
        "        if real==1:\r\n",
        "          test_df_without_data.at[idx,\"status\"] = \"False Negative\"\r\n",
        "        else:\r\n",
        "          test_df_without_data.at[idx,\"status\"] = \"False Positive\"        \r\n",
        "\r\n",
        "      if predict==0:\r\n",
        "        not_predicted_as_attractive_idx_without_data.append(idx)\r\n",
        "      idx+=1\r\n",
        "\r\n",
        "print(total)\r\n",
        "print(correct)\r\n",
        "\r\n",
        "print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\r\n",
        "    len(testset), 100 * correct.true_divide(total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b6Q2ZKEdxOZ"
      },
      "source": [
        "test_df_without_data['predicted_value']= test_df_without_data['predicted_value'].apply(lambda x : float(x))\r\n",
        "attractive_predicted_df = test_df_without_data.drop(not_predicted_as_attractive_idx)\r\n",
        "attractive_predicted_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYhAk7q0cWmv"
      },
      "source": [
        "## Best and worst classified pictures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TB6uSRMzd8DZ"
      },
      "source": [
        "**1. Least attractive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RfZiXMod_jv"
      },
      "source": [
        "test_df_without_data.sort_values(by='predicted_value', ascending=False).head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5Fi8EOucu5v"
      },
      "source": [
        "#Least attractive pictures\r\n",
        "path0 = r'lesimages/img_align_celeba/'+'195079.jpg'\r\n",
        "img0 = cv2.imread(path0) \r\n",
        "cv2_imshow(img0)\r\n",
        "\r\n",
        "path1 = r'lesimages/img_align_celeba/'+'183494.jpg'\r\n",
        "img1 = cv2.imread(path1) \r\n",
        "cv2_imshow(img1)\r\n",
        "\r\n",
        "path2 = r'lesimages/img_align_celeba/'+'200832.jpg'\r\n",
        "img2 = cv2.imread(path2) \r\n",
        "cv2_imshow(img2)\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0OfXGP6eVM7"
      },
      "source": [
        "**2. Most attractive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiQIFulqeX5w"
      },
      "source": [
        "test_df_without_data.sort_values(by='predicted_value').head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YR1x63JXc5cj"
      },
      "source": [
        "#Most attractive pictures\r\n",
        "path0 = r'lesimages/img_align_celeba/'+'190946.jpg'\r\n",
        "img0 = cv2.imread(path0) \r\n",
        "cv2_imshow(img0)\r\n",
        "\r\n",
        "path1 = r'lesimages/img_align_celeba/'+'192318.jpg'\r\n",
        "img1 = cv2.imread(path1) \r\n",
        "cv2_imshow(img1)\r\n",
        "\r\n",
        "path2 = r'lesimages/img_align_celeba/'+'202063.jpg'\r\n",
        "img2 = cv2.imread(path2) \r\n",
        "cv2_imshow(img2)\t"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDNmBf4netif"
      },
      "source": [
        "## Attributes amongst populations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWtTLHbqey3X"
      },
      "source": [
        "ici les bar plot des distributions des populations, des false positive etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLhbcmABb6JF"
      },
      "source": [
        "# Fairness evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbTe4d-tcCHU"
      },
      "source": [
        "### Attribute \"Young\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08raA9F_b9bK"
      },
      "source": [
        "test_df = test_df_without_data\r\n",
        "\r\n",
        "print(\"----------STATISCTICS WITHOUT DATA ----------\")\r\n",
        "\r\n",
        "print(\"GROUP FAIRNESS REGARDING YOUNG\")\r\n",
        "#P(M(X)=1 | A=a) = P(M(X)=1 | B=b)\r\n",
        "print(len(test_df[(test_df[\"status\"].isin([\"False Positive\",\"True Positive\"])) & (test_df[\"Young\"]==True)])/len(test_df[test_df[\"Young\"]==True]))\r\n",
        "print(len(test_df[(test_df[\"status\"].isin([\"False Positive\",\"True Positive\"])) & (test_df[\"Young\"]==False)])/len(test_df[test_df[\"Young\"]==False]))\r\n",
        "print(\"\\n\")\r\n",
        "print(\"EQUALIZED ODDS\")\r\n",
        "print(\"\\n\")\r\n",
        "print(\"True Positive \")\r\n",
        "#P(M(X)=1 | A=a, y=1) = P(M(X)=1 | A=b, y=1)\r\n",
        "print(\"--------------\")\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"True Positive\") & (test_df[\"Young\"]==True)])/len(test_df[(test_df[\"status\"].isin([\"False Negative\",\"True Positive\"])) & (test_df[\"Young\"]==True)]))\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"True Positive\") & (test_df[\"Young\"]==False)])/len(test_df[(test_df[\"status\"].isin([\"False Negative\",\"True Positive\"])) & (test_df[\"Young\"]==False)]))\r\n",
        "print(\"\\n\")\r\n",
        "print(\"False Positive \")\r\n",
        "#P(M(X)=1 | A=a, y=0) = P(M(X)=1 | A=b, y=0)\r\n",
        "print(\"----------------\")\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"False Positive\") & (test_df[\"Young\"]==True)])/len(test_df[(test_df[\"status\"].isin([\"True Negative\",\"False Positive\"])) & (test_df[\"Young\"]==True)]))\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"False Positive\") & (test_df[\"Young\"]==False)])/len(test_df[(test_df[\"status\"].isin([\"True Negative\",\"False Positive\"])) & (test_df[\"Young\"]==False)]))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3bXJEpYcF0N"
      },
      "source": [
        "### Attribute \"Bald\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaKLbzczcJpD"
      },
      "source": [
        "test_df = test_df_with_data\r\n",
        "\r\n",
        "print(\"----------STATISCTICS WITH DATA ----------\")\r\n",
        "\r\n",
        "print(\"GROUP FAIRNESS REGARDING Bald\")\r\n",
        "#P(M(X)=1 | A=a) = P(M(X)=1 | B=b)\r\n",
        "print(len(test_df[(test_df[\"status\"].isin([\"False Positive\",\"True Positive\"])) & (test_df[\"Bald\"]==True)])/len(test_df[test_df[\"Bald\"]==True]))\r\n",
        "print(len(test_df[(test_df[\"status\"].isin([\"False Positive\",\"True Positive\"])) & (test_df[\"Bald\"]==False)])/len(test_df[test_df[\"Bald\"]==False]))\r\n",
        "print(\"\\n\")\r\n",
        "print(\"EQUALIZED ODDS\")\r\n",
        "print(\"\\n\")\r\n",
        "print(\"True Positive \")\r\n",
        "#P(M(X)=1 | A=a, y=1) = P(M(X)=1 | A=b, y=1)\r\n",
        "print(\"--------------\")\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"True Positive\") & (test_df[\"Bald\"]==True)])/len(test_df[(test_df[\"status\"].isin([\"False Negative\",\"True Positive\"])) & (test_df[\"Bald\"]==True)]))\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"True Positive\") & (test_df[\"Bald\"]==False)])/len(test_df[(test_df[\"status\"].isin([\"False Negative\",\"True Positive\"])) & (test_df[\"Bald\"]==False)]))\r\n",
        "print(\"\\n\")\r\n",
        "print(\"False Positive \")\r\n",
        "#P(M(X)=1 | A=a, y=0) = P(M(X)=1 | A=b, y=0)\r\n",
        "print(\"----------------\")\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"False Positive\") & (test_df[\"Bald\"]==True)])/len(test_df[(test_df[\"status\"].isin([\"True Negative\",\"False Positive\"])) & (test_df[\"Bald\"]==True)]))\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"False Positive\") & (test_df[\"Bald\"]==False)])/len(test_df[(test_df[\"status\"].isin([\"True Negative\",\"False Positive\"])) & (test_df[\"Bald\"]==False)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSFCG-qfe79X"
      },
      "source": [
        "# First fix : Adjusting the treshold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AG7LMMgmfcHQ"
      },
      "source": [
        "## Calculating the rates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzn0njEFfjBS"
      },
      "source": [
        " def get_rates(treshold, attr):\r\n",
        "  #create the dataframe\r\n",
        "  test_df = pd.DataFrame(testset_allattr)\r\n",
        "  test_df.columns = [\"image_link\",\"attrs\"]\r\n",
        "  test_df[[key for key in testset.attr2idx.keys()]] = test_df['attrs'].apply(pd.Series)\r\n",
        "  test_df.pop(\"attrs\")\r\n",
        "  test_df[\"status\"]=[\"Not_known_yet\" for i in range(len(test_df.index))]\r\n",
        "  test_df.head()\r\n",
        "\r\n",
        "  #do the test\r\n",
        "  correct = 0\r\n",
        "  total = 0\r\n",
        "  idx = 0 \r\n",
        "  not_predicted_as_attractive_idx = []\r\n",
        "\r\n",
        "  net.eval()\r\n",
        "  for data in testloader:\r\n",
        "      images, labels = data\r\n",
        "      labels = labels.cuda()\r\n",
        "      outputs = net(images.cuda())\r\n",
        "      #round at desired treshold round(x - treshold + 0.5)\r\n",
        "      predicted = torch.round(outputs.data - treshold + 0.5) #treshold changes here\r\n",
        "      predicted = predicted.cuda()\r\n",
        "      total += labels.size(0)\r\n",
        "      correct += (predicted == labels).sum()\r\n",
        "\r\n",
        "      for predict,real in zip(predicted,labels):\r\n",
        "\r\n",
        "        if predict==real:\r\n",
        "          if real==1:\r\n",
        "            test_df.at[idx,\"status\"] = \"True Positive\"\r\n",
        "          else:\r\n",
        "            test_df.at[idx,\"status\"] = \"True Negative\"\r\n",
        "        else:\r\n",
        "          if real==1:\r\n",
        "            test_df.at[idx,\"status\"] = \"False Negative\"\r\n",
        "          else:\r\n",
        "            test_df.at[idx,\"status\"] = \"False Positive\"        \r\n",
        "\r\n",
        "        if predict==0:\r\n",
        "          not_predicted_as_attractive_idx.append(idx)\r\n",
        "        idx+=1\r\n",
        "\r\n",
        "  print(\"treshold : \" + str(treshold)+'\\n')\r\n",
        "  print(total)\r\n",
        "  print(correct)\r\n",
        "  #ici nous on a pas testset.data\r\n",
        "  print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\r\n",
        "      len(testset), 100 * correct.true_divide(total)))\r\n",
        "\r\n",
        "  #false positive rate with attribute\r\n",
        "  fp_w = len(test_df[(test_df[\"status\"]==\"False Positive\") & (test_df[attr]==True)])/len(test_df[(test_df[\"status\"].isin([\"True Negative\",\"False Positive\"])) & (test_df[attr]==True)])\r\n",
        "  #true positive rate with attribute\r\n",
        "  tp_w = len(test_df[(test_df[\"status\"]==\"True Positive\") & (test_df[attr]==True)])/len(test_df[(test_df[\"status\"].isin([\"False Negative\",\"True Positive\"])) & (test_df[attr]==True)])\r\n",
        "  #false positive rate without attribute\r\n",
        "  fp_wo = len(test_df[(test_df[\"status\"]==\"False Positive\") & (test_df[attr]==False)])/len(test_df[(test_df[\"status\"].isin([\"True Negative\",\"False Positive\"])) & (test_df[attr]==False)])\r\n",
        "  #true positive rate without attribute\r\n",
        "  tp_wo = len(test_df[(test_df[\"status\"]==\"True Positive\") & (test_df[attr]==False)])/len(test_df[(test_df[\"status\"].isin([\"False Negative\",\"True Positive\"])) & (test_df[attr]==False)])\r\n",
        "\r\n",
        "  return tp_w, fp_w, tp_wo, fp_wo"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mpo-N9yfu4Q"
      },
      "source": [
        "## Plotting the ROC curves"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfAwoKJNfwvD"
      },
      "source": [
        "category = 'Eyeglasses'\r\n",
        "i = 0\r\n",
        "x_w = []\r\n",
        "y_w = []\r\n",
        "x_wo = []\r\n",
        "y_wo = []\r\n",
        "interval = np.arange(0,1,0.05)\r\n",
        "for t in interval:\r\n",
        "  result = get_rates(t, category)\r\n",
        "  y_w.append(result[0])\r\n",
        "  x_w.append(result[1])\r\n",
        "  y_wo.append(result[2])\r\n",
        "  x_wo.append(result[3])\r\n",
        "\r\n",
        "plt.plot(x_w,y_w, label = category, color = 'pink' )\r\n",
        "plt.plot(x_wo,y_wo, label = 'wo'+category, color = 'blue')\r\n",
        "plt.legend(title='ROC curves for the Eyeglasses attribute')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pggUhVPwgYOC"
      },
      "source": [
        "## Finding the tresholds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZQKZoQEgZ_F"
      },
      "source": [
        "#Printing the rates\r\n",
        "print('TPR for eyeglasses')\r\n",
        "print(x_w)\r\n",
        "print('FPR for eyeglasses')\r\n",
        "print(y_w)\r\n",
        "print('TPR without eyeglasses')\r\n",
        "print(x_wo)\r\n",
        "print('FPR without eyeglasses')\r\n",
        "print(y_wo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvKHJLpzgqtX"
      },
      "source": [
        "We choose tresholds so that the rates are equal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-WwAcAWgjLr"
      },
      "source": [
        "#Choosing a treshold of 0.4 for people with eyeglasses\r\n",
        "print(get_rates(0.4, \"Eyeglasses\"))\r\n",
        "#with eye glasses :\r\n",
        "#true positive rate : 0.46601941747572817\r\n",
        "#false positive rate : 0.05227655986509275"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNPcbT4zgn0S"
      },
      "source": [
        "#Choosing a treshold of 0.4 for people without eyeglasses\r\n",
        "print(get_rates(0.8, \"Eyeglasses\"))\r\n",
        "#without eye glasses :\r\n",
        "#true positive rate : 0.46074527820316485\r\n",
        "#false positive rate : 0.04178869114665465"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnsUaARfg5bH"
      },
      "source": [
        "## Recalculating the fairness metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2Bq4f0ng9BV"
      },
      "source": [
        "print(\"----------STATISCTICS----------\")\r\n",
        "\r\n",
        "print(\"GROUP FAIRNESS REGARDING Eyeglasses\")\r\n",
        "#P(M(X)=1 | A=a) = P(M(X)=1 | B=b)\r\n",
        "print(len(test_df[(test_df[\"status\"].isin([\"False Positive\",\"True Positive\"])) & (test_df[\"Eyeglasses\"]==True)])/len(test_df[test_df[\"Eyeglasses\"]==True]))\r\n",
        "print(len(test_df[(test_df[\"status\"].isin([\"False Positive\",\"True Positive\"])) & (test_df[\"Eyeglasses\"]==False)])/len(test_df[test_df[\"Eyeglasses\"]==False]))\r\n",
        "print(\"\\n\")\r\n",
        "print(\"EQUALIZED ODDS\")\r\n",
        "print(\"\\n\")\r\n",
        "print(\"True Positive \")\r\n",
        "#P(M(X)=1 | A=a, y=1) = P(M(X)=1 | A=b, y=1)\r\n",
        "print(\"--------------\")\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"True Positive\") & (test_df[\"Eyeglasses\"]==True)])/len(test_df[(test_df[\"status\"].isin([\"False Negative\",\"True Positive\"])) & (test_df[\"Eyeglasses\"]==True)]))\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"True Positive\") & (test_df[\"Eyeglasses\"]==False)])/len(test_df[(test_df[\"status\"].isin([\"False Negative\",\"True Positive\"])) & (test_df[\"Eyeglasses\"]==False)]))\r\n",
        "print(\"\\n\")\r\n",
        "print(\"False Positive \")\r\n",
        "#P(M(X)=1 | A=a, y=0) = P(M(X)=1 | A=b, y=0)\r\n",
        "print(\"----------------\")\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"False Positive\") & (test_df[\"Eyeglasses\"]==True)])/len(test_df[(test_df[\"status\"].isin([\"True Negative\",\"False Positive\"])) & (test_df[\"Eyeglasses\"]==True)]))\r\n",
        "print(len(test_df[(test_df[\"status\"]==\"False Positive\") & (test_df[\"Eyeglasses\"]==False)])/len(test_df[(test_df[\"status\"].isin([\"True Negative\",\"False Positive\"])) & (test_df[\"Eyeglasses\"]==False)]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tt_HAEUbxkb"
      },
      "source": [
        "# Second fix : Adding data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gA8hORtag5j"
      },
      "source": [
        "## With added data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5c85NSNap4E"
      },
      "source": [
        "un petit texte pour expliquer quel mod√®le charger + quoi commenter/decommenter dans le dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEEmkEK4ajyZ"
      },
      "source": [
        "##### TEST DATAFRAME #####\r\n",
        "test_df_with_data = pd.DataFrame(testset_allattr)\r\n",
        "test_df_with_data.columns = [\"image_link\",\"attrs\"]\r\n",
        "test_df_with_data[[key for key in testset.attr2idx.keys()]] = test_df_with_data['attrs'].apply(pd.Series)\r\n",
        "test_df_with_data.pop(\"attrs\")\r\n",
        "test_df_with_data[\"status\"]=[\"Not_known_yet\" for i in range(len(test_df_with_data.index))]\r\n",
        "test_df_with_data[\"predicted_value\"]=[str(0) for i in range(len(test_df_with_data.index))]\r\n",
        "\r\n",
        "##### TRAIN DATAFRAME #####\r\n",
        "train_df_with_data = pd.DataFrame(trainset_allattr)\r\n",
        "train_df_with_data.columns = [\"image_link\",\"attrs\"]\r\n",
        "train_df_with_data[[key for key in trainset.attr2idx.keys()]] = train_df_with_data['attrs'].apply(pd.Series)\r\n",
        "del train_df_with_data[\"attrs\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBn4wa3ca8ab"
      },
      "source": [
        "### Testing the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suIK1uyta6Tz"
      },
      "source": [
        "correct = 0\r\n",
        "total = 0\r\n",
        "idx = 0 \r\n",
        "not_predicted_as_attractive_idx_with_data = []\r\n",
        "\r\n",
        "net.eval()\r\n",
        "for data in testloader:\r\n",
        "    images, labels = data\r\n",
        "    labels = labels.cuda()\r\n",
        "    outputs = net(images.cuda())\r\n",
        "    predicted_raw = outputs.data\r\n",
        "    predicted = torch.round(outputs.data)\r\n",
        "    predicted = predicted.cuda()\r\n",
        "    total += labels.size(0)\r\n",
        "    correct += (predicted == labels).sum()\r\n",
        "    for predict,predict_raw, real in zip(predicted,predicted_raw,labels):\r\n",
        "      test_df_with_data.at[idx,\"predicted_value\"] = str(predict_raw.item())\r\n",
        "      if predict==real:\r\n",
        "        if real==1:\r\n",
        "          test_df_with_data.at[idx,\"status\"] = \"True Positive\"\r\n",
        "        else:\r\n",
        "          test_df_with_data.at[idx,\"status\"] = \"True Negative\"\r\n",
        "      else:\r\n",
        "        if real==1:\r\n",
        "          test_df_with_data.at[idx,\"status\"] = \"False Negative\"\r\n",
        "        else:\r\n",
        "          test_df_with_data.at[idx,\"status\"] = \"False Positive\"        \r\n",
        "\r\n",
        "      if predict==0:\r\n",
        "        not_predicted_as_attractive_idx_with_data.append(idx)\r\n",
        "      idx+=1\r\n",
        "\r\n",
        "print(total)\r\n",
        "print(correct)\r\n",
        "\r\n",
        "print('Accuracy of the network on the {} test images: {:4.2f} %'.format(\r\n",
        "    len(testset), 100 * correct.true_divide(total)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt4M7D31bCKj"
      },
      "source": [
        "## Comparison between with and without added data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ8ENvQVbHtw"
      },
      "source": [
        "### Proportion of attributes\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25bwPM_JbFnE"
      },
      "source": [
        "# Set up a grid of plots\r\n",
        "fig = plt.figure(figsize=(10,5)) \r\n",
        "\r\n",
        "# Plot accidents depending on type\r\n",
        "x_attr = list(trainset.attr2idx.keys())\r\n",
        "x_attr.remove(\"Attractive\")\r\n",
        "\r\n",
        "i=1\r\n",
        "barWidth = 0.25\r\n",
        "\r\n",
        "for attr in x_attr:\r\n",
        "    y_percentage_without_data = len(train_df_without_data[train_df_without_data[attr]==True])/len(train_df_without_data)\r\n",
        "    y_percentage_with_data = len(train_df_with_data[train_df_with_data[attr]==True])/len(train_df_with_data)\r\n",
        "\r\n",
        "    plt.bar(i,y_percentage_without_data,color='#B22222',width=barWidth,label=\"w/o adding data\" if i==1 else \"\")\r\n",
        "    plt.bar(i+barWidth,y_percentage_with_data,color='#F08080',width=barWidth,label=\"w adding data\" if i==1 else \"\")\r\n",
        "    i+=1\r\n",
        "\r\n",
        "barWidth = 0.25\r\n",
        "\r\n",
        "plt.xticks([r + barWidth/2 for r in range(1,len(x_attr)+1)], [attr for attr in x_attr],rotation=90)\r\n",
        "plt.legend(prop={'size': 12})\r\n",
        "plt.title(\"Proportion of selected attributes inside different population\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}